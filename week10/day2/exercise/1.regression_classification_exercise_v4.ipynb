{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pro 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto que con GridSearch se puede hacer una búsqueda de los mejores parámetros para los algoritmos:\n",
    "\n",
    "- Realiza los cambios necesarios en tu programa del archivo \"3.regression_classification_exercise\" del CW8D4/ para que exista una opción en la que el usuario pueda elegir uno o más de un algoritmo y encontrar las mejores features para cada uno de los algoritmos seleccionados a partir del atributo \"params\" que pasa por parámetro. Ahora \"params\" es una lista de diccionarios. \n",
    "\n",
    "### Pipeline:\n",
    "\n",
    "1. El usuario define: \"params\", el \"dataframe\" con el target, el \"target_name\" y la decisión del usuario. Para el dataframe, puedes usar el método genérico de limpieza creado en el ejercicio CW9D3/exercises/4.cleaning_general.\n",
    "\n",
    "2. Se ejecuta main() usando todas esas variables anteriormente definidas.\n",
    "\n",
    "3. Se elige el modelo o modelos.\n",
    "\n",
    "4. Se crean los conjuntos X, y (con su split necesario).\n",
    "\n",
    "5. Se realiza el GridSearch utilizando los algoritmos que el usuario haya elegido.\n",
    "\n",
    "6. Una vez que se sepa cuál es el mejor modelo con las mejores features, se realiza el entrenamiento. Se recomienda utilizar con RepeatedStratifiedKFold (validación cruzada).\n",
    "\n",
    "7. Se retorna el accuracy del conjunto de test por cada modelo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de params con un solo elemento (elección de un único modelo)\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': np.logspace(0, 4, 10)\n",
    "    }\n",
    "\n",
    "params = [logistic_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de params con un solo elemento (elección de un único modelo)\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': np.logspace(0, 4, 10)\n",
    "    }\n",
    "\n",
    "random_forest_params = {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__n_estimators': [10, 100, 1000],\n",
    "    'classifier__max_features': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "svm_params = {\n",
    "    'classifier': [svm.SVC()],\n",
    "    'classifier__kernel':('linear', 'rbf', 'sigmoid'), \n",
    "    'classifier__C':[0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "    'classifier__degree': to_test,\n",
    "    'classifier__coef0': [-10.,-1., 0., 0.1, 0.5, 1, 10, 100],\n",
    "    'classifier__gamma': ('scale', 'auto')\n",
    "    }\n",
    "\n",
    "params = [\n",
    "    logistic_params,\n",
    "    random_forest_params,\n",
    "    svm_params\n",
    "    ]"
   ]
  }
 ]
}